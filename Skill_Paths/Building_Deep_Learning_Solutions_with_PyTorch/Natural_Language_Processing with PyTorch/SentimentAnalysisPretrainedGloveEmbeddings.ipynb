{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torchtext import datasets\n",
    "import torch.optim as optim\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>neg</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>neg</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID Sentiment SentimentSource  \\\n",
       "0       1       neg    Sentiment140   \n",
       "1       2       neg    Sentiment140   \n",
       "2       3       pos    Sentiment140   \n",
       "3       4       neg    Sentiment140   \n",
       "4       5       neg    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \n",
       "0                       is so sad for my APL frie...  \n",
       "1                     I missed the New Moon trail...  \n",
       "2                            omg its already 7:30 :O  \n",
       "3  .. Omgaga. Im sooo  im gunna CRy. I've been at...  \n",
       "4           i think mi bf is cheating on me!!!   ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"datasets/tweets/tweets.csv\", on_bad_lines=\"skip\")\n",
    "tweets = tweets.head(50000)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                      SentimentText\n",
       "0       neg                       is so sad for my APL frie...\n",
       "1       neg                     I missed the New Moon trail...\n",
       "2       pos                            omg its already 7:30 :O\n",
       "3       neg  .. Omgaga. Im sooo  im gunna CRy. I've been at...\n",
       "4       neg           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(columns=[\"ItemID\", \"SentimentSource\"], axis=1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"Sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    26921\n",
       "neg    23079\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.Sentiment.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Labels')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = sns.barplot(x=tweets.Sentiment.unique(), y=tweets.Sentiment.value_counts())\n",
    "ax.set(xlabel=\"Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(tweets, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Sentiment                                      SentimentText\n",
       " 0           pos  @amyrenea omg so am I lol I fell asleep when i...\n",
       " 1           neg               @Adrienne_Bailon I want a shout out \n",
       " 2           neg  @Anonymousboy03 Plans for school stuff &amp; a...\n",
       " 3           neg  ... has hit a writer's block .. am loosing my ...\n",
       " 4           neg  ... trying to find people I know! I`m bored, i...\n",
       " ...         ...                                                ...\n",
       " 39995       pos   #robotpickuplines are so funny. check them out. \n",
       " 39996       pos  @annyo84 awh thankss.  yeah, i understand what...\n",
       " 39997       pos  @AmbiguityX ohh you're in twin cities?  i luv ...\n",
       " 39998       neg   Dinara lost again in Roland Garros. Why the S...\n",
       " 39999       pos  *yawn* fucking time zones shit. I'm really sic...\n",
       " \n",
       " [40000 rows x 2 columns],\n",
       "      Sentiment                                      SentimentText\n",
       " 0          pos  @aimeesays aww i hope it does fly by because J...\n",
       " 1          neg  #dontyouhate when you JUST painted yur nails a...\n",
       " 2          neg  - @EvertB which one? http://bit.ly/10o8LW, htt...\n",
       " 3          pos  *shriek* Bee almost flew here from window. I'm...\n",
       " 4          pos  @Alyssa_Milano granted if we lose it is to a w...\n",
       " ...        ...                                                ...\n",
       " 9995       neg  @aisforamylynn you're a badass for having a ba...\n",
       " 9996       pos  @acts_rox  I'm not particular about it being f...\n",
       " 9997       pos                     @@j311stp and the same to you!\n",
       " 9998       pos  .@nanere Sheila I heart you!! That &quot;Holly...\n",
       " 9999       neg   not the same without a goodnight....hm. Wish ...\n",
       " \n",
       " [10000 rows x 2 columns])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True), test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"datasets/tweets/train_tweets.csv\", index=False)\n",
    "test.to_csv(\"datasets/tweets/test_tweets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_clean(text):\n",
    "    text = re.sub(r\"[^A-Za-z0-9]+\", \" \", text)\n",
    "    text = re.sub(r\"https?:/\\/\\S+\", \" \", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"tagger\", \"ner\"])\n",
    "\n",
    "\n",
    "def tokenizer(s):\n",
    "    return [w.text.lower() for w in nlp(tweet_clean(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(tokenize=tokenizer)\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafields = [(\"Sentiment\", LABEL), (\"SentimentText\", TEXT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "trn, tst = torchtext.data.TabularDataset.splits(\n",
    "    path=\"datasets/tweets/\",\n",
    "    train=\"train_tweets.csv\",\n",
    "    test=\"test_tweets.csv\",\n",
    "    format=\"csv\",\n",
    "    skip_header=True,\n",
    "    fields=datafields,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training exampes: 40000\n",
      "Number of testing examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training exampes: {len(trn)}\")\n",
    "print(f\"Number of testing examples: {len(tst)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentiment': 'pos',\n",
       " 'SentimentText': ['amyrenea',\n",
       "  'omg',\n",
       "  'so',\n",
       "  'am',\n",
       "  'i',\n",
       "  'lol',\n",
       "  'i',\n",
       "  'fell',\n",
       "  'asleep',\n",
       "  'when',\n",
       "  'it',\n",
       "  'was',\n",
       "  'on',\n",
       "  'last',\n",
       "  'night',\n",
       "  'so',\n",
       "  'now',\n",
       "  'i',\n",
       "  'get',\n",
       "  'to',\n",
       "  'finish',\n",
       "  'it']}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(trn.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(\n",
    "    trn, max_size=25000, vectors=\"glove.6B.100d\", unk_init=torch.Tensor.normal_\n",
    ")\n",
    "LABEL.build_vocab(trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 25644), ('the', 12219), ('to', 12111), ('you', 10723), ('a', 9197), ('it', 8440), ('and', 6889), ('my', 6208), ('quot', 5582), ('s', 5565), ('that', 5306), ('is', 5203), ('for', 4971), ('in', 4852), ('t', 4844), ('m', 4683), ('me', 4588), ('of', 4331), ('on', 3918), ('have', 3752), ('so', 3612), ('but', 3506), ('be', 2932), ('not', 2887), ('was', 2775), ('just', 2724), ('can', 2523), ('do', 2418), ('are', 2351), ('your', 2320), ('with', 2269), ('good', 2203), ('like', 2173), ('at', 2131), ('no', 2119), ('this', 2094), ('all', 2069), ('up', 2066), ('now', 2063), ('get', 2044), ('we', 1988), ('u', 1890), ('love', 1885), ('lol', 1864), ('too', 1826), ('what', 1760), ('out', 1742), ('know', 1664), ('nt', 1608), ('amp', 1539)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'i', 'the', 'to', 'you', 'a', 'it', 'and', 'my']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'pos': 0, 'neg': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
    "    (trn, tst),\n",
    "    batch_size=64,\n",
    "    sort_key=lambda x: len(x.SentimentText),\n",
    "    sort_within_batch=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        n_layers,\n",
    "        bidirectional,\n",
    "        dropout,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=n_layers,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        return self.fc(hidden.squeeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 20\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(\n",
    "    input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(25002, 100)\n",
       "  (rnn): GRU(100, 20, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=40, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "print(pretrained_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5646,  0.7396, -0.8372,  ...,  0.8436,  1.1336, -0.7308],\n",
       "        [-0.5556,  0.2236, -2.0112,  ...,  1.1270,  0.7417, -0.1556],\n",
       "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
       "        ...,\n",
       "        [-0.5211,  0.0658,  0.0974,  ...,  0.3269,  0.4554,  1.2100],\n",
       "        [-0.0722,  0.6892,  0.0027,  ...,  0.9599, -0.2160,  1.6911],\n",
       "        [ 1.6255, -0.6749,  1.5421,  ...,  0.5531,  2.3623, -1.0693]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
      "        ...,\n",
      "        [-0.5211,  0.0658,  0.0974,  ...,  0.3269,  0.4554,  1.2100],\n",
      "        [-0.0722,  0.6892,  0.0027,  ...,  0.9599, -0.2160,  1.6911],\n",
      "        [ 1.6255, -0.6749,  1.5421,  ...,  0.5531,  2.3623, -1.0693]])\n"
     ]
    }
   ],
   "source": [
    "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
    "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
    "\n",
    "print(model.embedding.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.Sentiment).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.635 | Train Acc: 62.95% |\n",
      "| Epoch: 02 | Train Loss: 0.541 | Train Acc: 73.32% |\n",
      "| Epoch: 03 | Train Loss: 0.496 | Train Acc: 76.01% |\n",
      "| Epoch: 04 | Train Loss: 0.472 | Train Acc: 77.54% |\n",
      "| Epoch: 05 | Train Loss: 0.447 | Train Acc: 79.39% |\n",
      "| Epoch: 06 | Train Loss: 0.428 | Train Acc: 80.47% |\n",
      "| Epoch: 07 | Train Loss: 0.409 | Train Acc: 81.42% |\n",
      "| Epoch: 08 | Train Loss: 0.392 | Train Acc: 82.57% |\n",
      "| Epoch: 09 | Train Loss: 0.380 | Train Acc: 83.09% |\n",
      "| Epoch: 10 | Train Loss: 0.368 | Train Acc: 83.98% |\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    print(\n",
    "        f\"| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.491 | Test Acc: 77.40%\n"
     ]
    }
   ],
   "source": [
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_iterator:\n",
    "        predictions = model(batch.SentimentText).squeeze(1)\n",
    "        loss = criterion(predictions, batch.Sentiment)\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.Sentiment).float()\n",
    "        acc = correct.sum() / len(correct)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "test_loss = epoch_loss / len(test_iterator)\n",
    "test_acc = epoch_acc / len(test_iterator)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence = \"I hate that show\"\n",
    "sentence = \"That move was really nice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [tok.text for tok in nlp.tokenizer(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = [TEXT.vocab.stoi[t] for t in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.LongTensor(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.sigmoid(model(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.319663941860199"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
