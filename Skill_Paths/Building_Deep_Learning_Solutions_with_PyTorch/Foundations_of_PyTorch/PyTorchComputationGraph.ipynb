{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37edf27b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.339501Z",
     "start_time": "2022-10-26T02:54:14.723051Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69546d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.355266Z",
     "start_time": "2022-10-26T02:54:15.340502Z"
    }
   },
   "outputs": [],
   "source": [
    "W = torch.randn(6)\n",
    "x = torch.tensor([10.0, 10.0, 10.0, 10.0, 10.0, 10.0])\n",
    "b = torch.tensor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895df689",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.370567Z",
     "start_time": "2022-10-26T02:54:15.357664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0920, -0.1484, -0.1798, -0.1728, -0.0897, -0.2095])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6751db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.386501Z",
     "start_time": "2022-10-26T02:54:15.371567Z"
    }
   },
   "outputs": [],
   "source": [
    "y = W * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c88644",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.401323Z",
     "start_time": "2022-10-26T02:54:15.388551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23.9197,  1.5162,  1.2023,  1.2715,  2.1033,  0.9054])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9367a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.416756Z",
     "start_time": "2022-10-26T02:54:15.402325Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.9197, -1.4838, -1.7977, -1.7285, -0.8967, -2.0946])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d588544",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.432074Z",
     "start_time": "2022-10-26T02:54:15.419930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6283626a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.447901Z",
     "start_time": "2022-10-26T02:54:15.436078Z"
    }
   },
   "outputs": [],
   "source": [
    "W1 = torch.tensor(6)\n",
    "W2 = torch.tensor(6)\n",
    "W3 = torch.tensor(6)\n",
    "\n",
    "x1 = torch.tensor([2, 2, 2])\n",
    "x2 = torch.tensor([3, 3, 3])\n",
    "x3 = torch.tensor([4, 4, 4])\n",
    "\n",
    "b = torch.tensor(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "138040e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.463049Z",
     "start_time": "2022-10-26T02:54:15.451604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6), tensor(6), tensor(6))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1, W2, W3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48d9abf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.477908Z",
     "start_time": "2022-10-26T02:54:15.464121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 30, 30])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_value = W1 * x1 + W2 * x2\n",
    "intermediate_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8030eca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.493012Z",
     "start_time": "2022-10-26T02:54:15.479916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([64, 64, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_value = W1 * x1 + W2 * x2 + W3 * x3 + b\n",
    "final_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd25be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.799529Z",
     "start_time": "2022-10-26T02:54:15.495014Z"
    }
   },
   "outputs": [],
   "source": [
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bdd1e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.815195Z",
     "start_time": "2022-10-26T02:54:15.804531Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.array(\n",
    "    [[1.7], [2.5], [5.5], [7.9], [8.8], [2.4], [2.4], [8.89], [5], [4.4]],\n",
    "    dtype=np.float32)\n",
    "\n",
    "y_train = np.array(\n",
    "    [[1.9], [2.68], [4.22], [8.19], [9.69], [3.4], [2.6], [8.8], [5.6], [4.7]],\n",
    "    dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad61dea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.830671Z",
     "start_time": "2022-10-26T02:54:15.818724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(x_train)\n",
    "Y_train = torch.tensor(y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b206bc62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.845713Z",
     "start_time": "2022-10-26T02:54:15.832672Z"
    }
   },
   "outputs": [],
   "source": [
    "inp = 1\n",
    "out = 1\n",
    "\n",
    "hid = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f328bc94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:15.861110Z",
     "start_time": "2022-10-26T02:54:15.847714Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = torch.nn.Sequential(torch.nn.Linear(\n",
    "    inp, hid), torch.nn.Linear(hid, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f46f5ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:16.541660Z",
     "start_time": "2022-10-26T02:54:15.863114Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%0 : Float(10, 1, strides=[1, 1], requires_grad=0, device=cpu),\n      %1 : Float(100, 1, strides=[1, 1], requires_grad=1, device=cpu),\n      %2 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(1, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %4 : Float(1, strides=[1], requires_grad=1, device=cpu)):\n  %15 : Float(10, 100, strides=[100, 1], requires_grad=1, device=cpu) = aten::linear(%0, %1, %2) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %16 : Float(10, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::linear(%15, %3, %4) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%16)\n, None, False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\hiddenlayer\\graph.py:143\u001b[0m, in \u001b[0;36mbuild_graph\u001b[1;34m(model, args, input_names, transforms, framework_transforms)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument args must be provided for Pytorch models.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 143\u001b[0m     \u001b[43mimport_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\hiddenlayer\\pytorch_builder.py:71\u001b[0m, in \u001b[0;36mimport_graph\u001b[1;34m(hl_graph, model, args, input_names, verbose)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_graph\u001b[39m(hl_graph, model, args, input_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# TODO: add input names to graph\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Run the Pytorch graph to get a trace and generate a graph from it\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     trace, out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_get_trace_graph(model, args)\n\u001b[1;32m---> 71\u001b[0m     torch_graph \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOperatorExportTypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mONNX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# Dump list of nodes (DEBUG only)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\onnx\\__init__.py:394\u001b[0m, in \u001b[0;36m_optimize_trace\u001b[1;34m(graph, operator_export_type)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize_trace\u001b[39m(graph, operator_export_type):\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\onnx\\utils.py:277\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[0;32m    275\u001b[0m symbolic_helper\u001b[38;5;241m.\u001b[39m_quantized_ops\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# Unpack quantized weights for conv and linear ops and insert into graph.\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx_unpack_quantized_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbolic_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_caffe2_aten_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m symbolic_helper\u001b[38;5;241m.\u001b[39mis_caffe2_aten_fallback():\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# Insert permutes before and after each conv op to ensure correct order.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_quantization_insert_permutes(graph, params_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: _jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%0 : Float(10, 1, strides=[1, 1], requires_grad=0, device=cpu),\n      %1 : Float(100, 1, strides=[1, 1], requires_grad=1, device=cpu),\n      %2 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(1, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %4 : Float(1, strides=[1], requires_grad=1, device=cpu)):\n  %15 : Float(10, 100, strides=[100, 1], requires_grad=1, device=cpu) = aten::linear(%0, %1, %2) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %16 : Float(10, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::linear(%15, %3, %4) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%16)\n, None, False"
     ]
    }
   ],
   "source": [
    "hl.build_graph(model1, torch.zeros([10, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d602a25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:21.066576Z",
     "start_time": "2022-10-26T02:54:21.034528Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%0 : Float(1, strides=[1], requires_grad=0, device=cpu),\n      %1 : Float(100, 1, strides=[1, 1], requires_grad=1, device=cpu),\n      %2 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(1, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %4 : Float(1, strides=[1], requires_grad=1, device=cpu)):\n  %15 : Float(100, strides=[1], requires_grad=1, device=cpu) = aten::linear(%0, %1, %2) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %16 : Float(1, strides=[1], requires_grad=1, device=cpu) = aten::linear(%15, %3, %4) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%16)\n, None, False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\hiddenlayer\\graph.py:143\u001b[0m, in \u001b[0;36mbuild_graph\u001b[1;34m(model, args, input_names, transforms, framework_transforms)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument args must be provided for Pytorch models.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 143\u001b[0m     \u001b[43mimport_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\hiddenlayer\\pytorch_builder.py:71\u001b[0m, in \u001b[0;36mimport_graph\u001b[1;34m(hl_graph, model, args, input_names, verbose)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_graph\u001b[39m(hl_graph, model, args, input_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# TODO: add input names to graph\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Run the Pytorch graph to get a trace and generate a graph from it\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     trace, out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_get_trace_graph(model, args)\n\u001b[1;32m---> 71\u001b[0m     torch_graph \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOperatorExportTypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mONNX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# Dump list of nodes (DEBUG only)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\onnx\\__init__.py:394\u001b[0m, in \u001b[0;36m_optimize_trace\u001b[1;34m(graph, operator_export_type)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize_trace\u001b[39m(graph, operator_export_type):\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\onnx\\utils.py:277\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[0;32m    275\u001b[0m symbolic_helper\u001b[38;5;241m.\u001b[39m_quantized_ops\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# Unpack quantized weights for conv and linear ops and insert into graph.\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx_unpack_quantized_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbolic_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_caffe2_aten_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m symbolic_helper\u001b[38;5;241m.\u001b[39mis_caffe2_aten_fallback():\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# Insert permutes before and after each conv op to ensure correct order.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_quantization_insert_permutes(graph, params_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: _jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%0 : Float(1, strides=[1], requires_grad=0, device=cpu),\n      %1 : Float(100, 1, strides=[1, 1], requires_grad=1, device=cpu),\n      %2 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(1, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %4 : Float(1, strides=[1], requires_grad=1, device=cpu)):\n  %15 : Float(100, strides=[1], requires_grad=1, device=cpu) = aten::linear(%0, %1, %2) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %16 : Float(1, strides=[1], requires_grad=1, device=cpu) = aten::linear(%15, %3, %4) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%16)\n, None, False"
     ]
    }
   ],
   "source": [
    "hl.build_graph(model1, torch.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33abdb14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:21.204320Z",
     "start_time": "2022-10-26T02:54:21.194806Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = torch.nn.Sequential(torch.nn.Linear(inp, hid),\n",
    "                             torch.nn.Linear(hid, hid),\n",
    "                             torch.nn.Sigmoid(),\n",
    "                             torch.nn.Linear(hid, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "640b45f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:54:21.388002Z",
     "start_time": "2022-10-26T02:54:21.356245Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%0 : Float(10, 1, strides=[1, 1], requires_grad=0, device=cpu),\n      %1 : Float(100, 1, strides=[1, 1], requires_grad=1, device=cpu),\n      %2 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(100, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %4 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %5 : Float(1, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %6 : Float(1, strides=[1], requires_grad=1, device=cpu)):\n  %21 : Float(10, 100, strides=[100, 1], requires_grad=1, device=cpu) = aten::linear(%0, %1, %2) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %22 : Float(10, 100, strides=[100, 1], requires_grad=1, device=cpu) = aten::linear(%21, %3, %4) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %23 : Float(10, 100, strides=[100, 1], requires_grad=1, device=cpu) = aten::sigmoid(%22) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\activation.py:290:0\n  %24 : Float(10, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::linear(%23, %5, %6) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%24)\n, None, False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\hiddenlayer\\graph.py:143\u001b[0m, in \u001b[0;36mbuild_graph\u001b[1;34m(model, args, input_names, transforms, framework_transforms)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument args must be provided for Pytorch models.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 143\u001b[0m     \u001b[43mimport_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\hiddenlayer\\pytorch_builder.py:71\u001b[0m, in \u001b[0;36mimport_graph\u001b[1;34m(hl_graph, model, args, input_names, verbose)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_graph\u001b[39m(hl_graph, model, args, input_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# TODO: add input names to graph\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Run the Pytorch graph to get a trace and generate a graph from it\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     trace, out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_get_trace_graph(model, args)\n\u001b[1;32m---> 71\u001b[0m     torch_graph \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOperatorExportTypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mONNX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# Dump list of nodes (DEBUG only)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\onnx\\__init__.py:394\u001b[0m, in \u001b[0;36m_optimize_trace\u001b[1;34m(graph, operator_export_type)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize_trace\u001b[39m(graph, operator_export_type):\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\onnx\\utils.py:277\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[0;32m    275\u001b[0m symbolic_helper\u001b[38;5;241m.\u001b[39m_quantized_ops\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# Unpack quantized weights for conv and linear ops and insert into graph.\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx_unpack_quantized_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbolic_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_caffe2_aten_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m symbolic_helper\u001b[38;5;241m.\u001b[39mis_caffe2_aten_fallback():\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# Insert permutes before and after each conv op to ensure correct order.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_quantization_insert_permutes(graph, params_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: _jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%0 : Float(10, 1, strides=[1, 1], requires_grad=0, device=cpu),\n      %1 : Float(100, 1, strides=[1, 1], requires_grad=1, device=cpu),\n      %2 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(100, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %4 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %5 : Float(1, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %6 : Float(1, strides=[1], requires_grad=1, device=cpu)):\n  %21 : Float(10, 100, strides=[100, 1], requires_grad=1, device=cpu) = aten::linear(%0, %1, %2) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %22 : Float(10, 100, strides=[100, 1], requires_grad=1, device=cpu) = aten::linear(%21, %3, %4) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %23 : Float(10, 100, strides=[100, 1], requires_grad=1, device=cpu) = aten::sigmoid(%22) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\activation.py:290:0\n  %24 : Float(10, 1, strides=[1, 1], requires_grad=1, device=cpu) = aten::linear(%23, %5, %6) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%24)\n, None, False"
     ]
    }
   ],
   "source": [
    "hl.build_graph(model2, torch.zeros([10, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "216f6fe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-26T02:55:48.638701Z",
     "start_time": "2022-10-26T02:55:48.597687Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%0 : Float(1, strides=[1], requires_grad=0, device=cpu),\n      %1 : Float(100, 1, strides=[1, 1], requires_grad=1, device=cpu),\n      %2 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(100, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %4 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %5 : Float(1, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %6 : Float(1, strides=[1], requires_grad=1, device=cpu)):\n  %21 : Float(100, strides=[1], requires_grad=1, device=cpu) = aten::linear(%0, %1, %2) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %22 : Float(100, strides=[1], requires_grad=1, device=cpu) = aten::linear(%21, %3, %4) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %23 : Float(100, strides=[1], requires_grad=1, device=cpu) = aten::sigmoid(%22) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\activation.py:290:0\n  %24 : Float(1, strides=[1], requires_grad=1, device=cpu) = aten::linear(%23, %5, %6) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%24)\n, None, False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\hiddenlayer\\graph.py:143\u001b[0m, in \u001b[0;36mbuild_graph\u001b[1;34m(model, args, input_names, transforms, framework_transforms)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument args must be provided for Pytorch models.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 143\u001b[0m     \u001b[43mimport_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_graph, FRAMEWORK_TRANSFORMS\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\hiddenlayer\\pytorch_builder.py:71\u001b[0m, in \u001b[0;36mimport_graph\u001b[1;34m(hl_graph, model, args, input_names, verbose)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimport_graph\u001b[39m(hl_graph, model, args, input_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# TODO: add input names to graph\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Run the Pytorch graph to get a trace and generate a graph from it\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     trace, out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_get_trace_graph(model, args)\n\u001b[1;32m---> 71\u001b[0m     torch_graph \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOperatorExportTypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mONNX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# Dump list of nodes (DEBUG only)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\onnx\\__init__.py:394\u001b[0m, in \u001b[0;36m_optimize_trace\u001b[1;34m(graph, operator_export_type)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize_trace\u001b[39m(graph, operator_export_type):\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\onnx\\utils.py:277\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[0;32m    275\u001b[0m symbolic_helper\u001b[38;5;241m.\u001b[39m_quantized_ops\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# Unpack quantized weights for conv and linear ops and insert into graph.\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx_unpack_quantized_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbolic_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_caffe2_aten_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m symbolic_helper\u001b[38;5;241m.\u001b[39mis_caffe2_aten_fallback():\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# Insert permutes before and after each conv op to ensure correct order.\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_quantization_insert_permutes(graph, params_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: _jit_pass_onnx_unpack_quantized_weights(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch::jit::Graph, arg1: Dict[str, IValue], arg2: bool) -> Dict[str, IValue]\n\nInvoked with: graph(%0 : Float(1, strides=[1], requires_grad=0, device=cpu),\n      %1 : Float(100, 1, strides=[1, 1], requires_grad=1, device=cpu),\n      %2 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %3 : Float(100, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %4 : Float(100, strides=[1], requires_grad=1, device=cpu),\n      %5 : Float(1, 100, strides=[100, 1], requires_grad=1, device=cpu),\n      %6 : Float(1, strides=[1], requires_grad=1, device=cpu)):\n  %21 : Float(100, strides=[1], requires_grad=1, device=cpu) = aten::linear(%0, %1, %2) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %22 : Float(100, strides=[1], requires_grad=1, device=cpu) = aten::linear(%21, %3, %4) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  %23 : Float(100, strides=[1], requires_grad=1, device=cpu) = aten::sigmoid(%22) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\activation.py:290:0\n  %24 : Float(1, strides=[1], requires_grad=1, device=cpu) = aten::linear(%23, %5, %6) # C:\\Users\\natha\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114:0\n  return (%24)\n, None, False"
     ]
    }
   ],
   "source": [
    "hl.build_graph(model2, torch.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215b471d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
